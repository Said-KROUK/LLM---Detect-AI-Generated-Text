{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":90929,"databundleVersionId":10665072,"sourceType":"competition"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/MagedSaeed/farasapy.git pyarabic Tashaphyne","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:28:10.905692Z","iopub.execute_input":"2025-01-11T16:28:10.906047Z","iopub.status.idle":"2025-01-11T16:28:18.600021Z","shell.execute_reply.started":"2025-01-11T16:28:10.906021Z","shell.execute_reply":"2025-01-11T16:28:18.598950Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/MagedSaeed/farasapy.git\n  Cloning https://github.com/MagedSaeed/farasapy.git to /tmp/pip-req-build-mtwwxh0g\n  Running command git clone --filter=blob:none --quiet https://github.com/MagedSaeed/farasapy.git /tmp/pip-req-build-mtwwxh0g\n  Resolved https://github.com/MagedSaeed/farasapy.git to commit 9200fb78f9e4d102a4b63b54b9b0ace84ff9d43e\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: pyarabic in /usr/local/lib/python3.10/dist-packages (0.6.15)\nCollecting Tashaphyne\n  Downloading Tashaphyne-0.3.6-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farasapy==0.0.14) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farasapy==0.0.14) (4.66.5)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from pyarabic) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy==0.0.14) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy==0.0.14) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy==0.0.14) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy==0.0.14) (2024.8.30)\nDownloading Tashaphyne-0.3.6-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.5/251.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: farasapy\n  Building wheel for farasapy (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for farasapy: filename=farasapy-0.0.14-py3-none-any.whl size=12920 sha256=a8e0e09d63926179501cbf7ef27d3518ea723aa04d795f477d458cacb58393d2\n  Stored in directory: /tmp/pip-ephem-wheel-cache-qsjo9h73/wheels/ae/56/72/2ba224ca1aa5d0822d5b1ea26be589d58732b74a6dd2a04f62\nSuccessfully built farasapy\nInstalling collected packages: Tashaphyne, farasapy\nSuccessfully installed Tashaphyne-0.3.6 farasapy-0.0.14\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport pandas as pd\nfrom transformers import AdamW\nfrom tqdm import tqdm\nfrom transformers import get_scheduler\nimport re\nimport regex\nfrom nltk.stem.isri import ISRIStemmer\nfrom nltk.stem.snowball import SnowballStemmer\nfrom pyarabic.araby import strip_tashkeel, strip_diacritics\nimport numpy as np\nimport pandas as pd\nimport pyarabic.araby as araby\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom farasa.stemmer import FarasaStemmer\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom tashaphyne.stemming import ArabicLightStemmer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:28:18.601236Z","iopub.execute_input":"2025-01-11T16:28:18.601481Z","iopub.status.idle":"2025-01-11T16:28:23.311746Z","shell.execute_reply.started":"2025-01-11T16:28:18.601461Z","shell.execute_reply":"2025-01-11T16:28:23.310831Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_set = pd.read_csv('/kaggle/input/c/detect-llm-generated-arabic-text/train_set.csv')\ndev_set = pd.read_csv('/kaggle/input/c/detect-llm-generated-arabic-text/dev_set.csv')\ntest_set = pd.read_csv('/kaggle/input/c/detect-llm-generated-arabic-text/test_set.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:28:23.313526Z","iopub.execute_input":"2025-01-11T16:28:23.313969Z","iopub.status.idle":"2025-01-11T16:28:24.001355Z","shell.execute_reply.started":"2025-01-11T16:28:23.313946Z","shell.execute_reply":"2025-01-11T16:28:24.000693Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def remove_stop_words(text):\n    Text=[i for i in str(text).split() if i not in arabic_stopwords]\n    return \" \".join(Text)\n\ndef ISRI_Stemmer(text):\n    #making an object\n    stemmer = ISRIStemmer()\n\n    #stemming each word\n    text = stemmer.stem(text)\n    text = stemmer.pre32(text)\n    text = stemmer.suf32(text)\n\n    return text\n\ndef Snowball_stemmer(text):\n    text = text.split()\n    #making an object\n    stemmer = SnowballStemmer(\"arabic\")\n\n    #stemming each word\n    text=[stemmer.stem(y) for y in text]\n\n    return \" \" .join(text)\n\ndef Arabic_Light_Stemmer(text):\n    #making an object\n    Arabic_Stemmer = ArabicLightStemmer()\n\n    #stemming each word\n    text=[Arabic_Stemmer.light_stem(y) for y in text.split()]\n\n    return \" \" .join(text)\n\ndef normalizeArabic(text):\n    text = text.strip()\n    text = re.sub(\"ى\", \"ي\", text)\n    text = re.sub(\"ؤ\", \"ء\", text)\n    text = re.sub(\"ئ\", \"ء\", text)\n    text = re.sub(\"ة\", \"ه\", text)\n\n    #remove repetetions\n    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n    text = text.replace('وو', 'و')\n    text = text.replace('يي', 'ي')\n    text = text.replace('ييي', 'ي')\n    text = text.replace('اا', 'ا')\n\n    ## remove extra whitespace\n    text = re.sub('\\s+', ' ', text)\n\n    # Remove longation\n    text = re.sub(r'(.)\\1+', r\"\\1\\1\", text)\n\n    #Strip vowels from a text, include Shadda.\n    text = araby.strip_tashkeel(text)\n\n    #Strip diacritics from a text, include harakats and small lettres The striped marks are\n    text = araby.strip_diacritics(text)\n    text=''.join([i for i in text if not i.isdigit()])\n    return text\n\ndef Removing_non_arabic(text):\n    text = re.sub('[A-Za-z]+',' ',text)\n    return text\n\ndef Removing_numbers(text):\n    text=''.join([i for i in text if not i.isdigit()])\n    return text\n\ndef Removing_punctuations(text):\n    ## Remove punctuations\n    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', text)\n    text = text.replace('؛',\"\", )\n\n    ## remove extra whitespace\n    text = re.sub('\\s+', ' ', text)\n    text =  \" \".join(text.split())\n    return text.strip()\n\ndef Removing_urls(text):\n    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_pattern.sub(r'', text)\ndef remove_extra_Space(text):\n    ## remove extra whitespace\n    text = re.sub('\\s+', ' ', text)\n    return  \" \".join(text.split())\n\ndef remove_small_sentences(df):\n    for i in range(len(df)):\n        if len(df.text.iloc[i].split()) < 3:\n            df.text.iloc[i] = np.nan\ndef apply_farasa_stemming(text):\n    \"\"\"\n    Applique le stemming à un texte en arabe en utilisant Farasa.\n\n    Args:\n        text (str): Le texte en arabe à traiter.\n\n    Returns:\n        str: Le texte après application du stemming.\n    \"\"\"\n    # Initialiser le stemmer\n    stemmer = FarasaStemmer()\n\n    # Appliquer le stemming\n    stemmed_text = stemmer.stem(text)\n\n    return stemmed_text\ndef preprocess_text(data):\n    \"\"\"\n    Preprocess text data by applying a series of cleaning functions.\n\n    Parameters:\n        data (pd.DataFrame): DataFrame containing the text data.\n        stopword_removal_func (function): Function to remove stopwords.\n        non_arabic_removal_func (function): Function to remove non-Arabic characters.\n        normalization_func (function): Function to normalize Arabic text.\n        number_removal_func (function): Function to remove numbers.\n        punctuation_removal_func (function): Function to remove punctuations.\n\n    Returns:\n        pd.DataFrame: Cleaned DataFrame.\n    \"\"\"\n    print('remove stop words')\n    data['text'] = data['text'].apply(lambda text: remove_stop_words(text))\n    print('remove non arabic')\n    data['text'] = data['text'].apply(lambda text: Removing_non_arabic(text))\n    print('normalize arabic')\n    data['text'] = data['text'].apply(lambda text: normalizeArabic(text))\n    print('remove numbers')\n    data['text'] = data['text'].apply(lambda text: Removing_numbers(text))\n    print('remove punctuations')\n    data['text'] = data['text'].apply(lambda text: Removing_punctuations(text))\n    # print('stemming')\n    # data['text'] = data['text'].apply(lambda text: Arabic_Light_Stemmer(text))\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:28:24.002561Z","iopub.execute_input":"2025-01-11T16:28:24.002813Z","iopub.status.idle":"2025-01-11T16:28:24.015625Z","shell.execute_reply.started":"2025-01-11T16:28:24.002792Z","shell.execute_reply":"2025-01-11T16:28:24.014685Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords # import stopwords\n\nnltk.download('stopwords')\n#are there any stop words in the data?\narabic_stopwords = stopwords.words(\"arabic\")\nlen(arabic_stopwords)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:28:24.016431Z","iopub.execute_input":"2025-01-11T16:28:24.016746Z","iopub.status.idle":"2025-01-11T16:28:24.100399Z","shell.execute_reply.started":"2025-01-11T16:28:24.016695Z","shell.execute_reply":"2025-01-11T16:28:24.099561Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"754"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train_set = preprocess_text(train_set)\n#train_set['text'] = train_set['text'].apply(preprocess_text)\ntrain_set.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:28:24.101205Z","iopub.execute_input":"2025-01-11T16:28:24.101426Z","iopub.status.idle":"2025-01-11T16:28:42.598933Z","shell.execute_reply.started":"2025-01-11T16:28:24.101407Z","shell.execute_reply":"2025-01-11T16:28:42.598109Z"}},"outputs":[{"name":"stdout","text":"remove stop words\nremove non arabic\nnormalize arabic\nremove numbers\nremove punctuations\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   text_id                                               text  generated\n0     9519  ارض السوار وكيف ظل البحاره يرفعون الاحمال والا...          0\n1     6247  وقال كيه لحسان » قل فوالله لقولك اشد عليهم وقع...          0\n2     3065  غابه ناءيه عميقه تسكن الاشجار الضخمه والنباتات...          1\n3      652  صميم قريه العتمه تتجذر اشجار الزيتون العتيقه ت...          1\n4     3447  قلب مدينه مزدحمه تنم يوما تتشابك الانوار الظلا...          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9519</td>\n      <td>ارض السوار وكيف ظل البحاره يرفعون الاحمال والا...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6247</td>\n      <td>وقال كيه لحسان » قل فوالله لقولك اشد عليهم وقع...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3065</td>\n      <td>غابه ناءيه عميقه تسكن الاشجار الضخمه والنباتات...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>652</td>\n      <td>صميم قريه العتمه تتجذر اشجار الزيتون العتيقه ت...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3447</td>\n      <td>قلب مدينه مزدحمه تنم يوما تتشابك الانوار الظلا...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"dev_set = preprocess_text(dev_set)\n# dev_set['text'] = dev_set['text'].apply(preprocess_text)\ndev_set.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:28:42.599859Z","iopub.execute_input":"2025-01-11T16:28:42.600126Z","iopub.status.idle":"2025-01-11T16:28:46.557313Z","shell.execute_reply.started":"2025-01-11T16:28:42.600102Z","shell.execute_reply":"2025-01-11T16:28:46.556556Z"}},"outputs":[{"name":"stdout","text":"remove stop words\nremove non arabic\nnormalize arabic\nremove numbers\nremove punctuations\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   text_id                                               text  generated\n0     2650  لحظه غامضه عندما انحنت الشمس الافق واخذت احضان...          1\n1     8091  وارسطو تكوين الطباع والكمال الحلقي للانسان » ا...          0\n2     3709  قلب المدينه القديمه تختلط الرواءح العتيقه والح...          1\n3    10437  غاليه البقميه حصنا منيعا السقوط المدوي ظلت اصد...          0\n4     3577  الجبال الشماليه كانت الرياح تعصف بالاشجار المي...          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2650</td>\n      <td>لحظه غامضه عندما انحنت الشمس الافق واخذت احضان...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8091</td>\n      <td>وارسطو تكوين الطباع والكمال الحلقي للانسان » ا...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3709</td>\n      <td>قلب المدينه القديمه تختلط الرواءح العتيقه والح...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10437</td>\n      <td>غاليه البقميه حصنا منيعا السقوط المدوي ظلت اصد...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3577</td>\n      <td>الجبال الشماليه كانت الرياح تعصف بالاشجار المي...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"test_set = preprocess_text(test_set)\n# test_set['text'] = test_set['text'].apply(preprocess_text)\ntest_set.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:28:46.559774Z","iopub.execute_input":"2025-01-11T16:28:46.560007Z","iopub.status.idle":"2025-01-11T16:28:50.543307Z","shell.execute_reply.started":"2025-01-11T16:28:46.559987Z","shell.execute_reply":"2025-01-11T16:28:50.542536Z"}},"outputs":[{"name":"stdout","text":"remove stop words\nremove non arabic\nnormalize arabic\nremove numbers\nremove punctuations\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   text_id                                               text\n0     2227  صحراء الجزيره العربيه الواسعه تتراقص الكثبان ا...\n1     6682  السواد سواد الشعر مولاناء مو دليل تعال شوف شنو...\n2     2649  وضعت قدميك حافه الرصيف تتراقص ظلال الاشجار الب...\n3     6652  وقف رجال الشراكسه صامتين ازاء هذاء وقد عقدوا ا...\n4     4296  انبلاج الفجر الافق ارتسمت اولي خيوط الشمس الحق...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2227</td>\n      <td>صحراء الجزيره العربيه الواسعه تتراقص الكثبان ا...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6682</td>\n      <td>السواد سواد الشعر مولاناء مو دليل تعال شوف شنو...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2649</td>\n      <td>وضعت قدميك حافه الرصيف تتراقص ظلال الاشجار الب...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6652</td>\n      <td>وقف رجال الشراكسه صامتين ازاء هذاء وقد عقدوا ا...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4296</td>\n      <td>انبلاج الفجر الافق ارتسمت اولي خيوط الشمس الحق...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"import torch\n\n# Vérifier si un GPU est disponible\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Utilisation du périphérique: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:28:50.544830Z","iopub.execute_input":"2025-01-11T16:28:50.545073Z","iopub.status.idle":"2025-01-11T16:28:50.620639Z","shell.execute_reply.started":"2025-01-11T16:28:50.545052Z","shell.execute_reply":"2025-01-11T16:28:50.619766Z"}},"outputs":[{"name":"stdout","text":"Utilisation du périphérique: cuda\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from transformers import BertTokenizer, BertModel\n\n# Charger le tokenizer et le modèle BERT\ntokenizer = BertTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\nmodel = BertModel.from_pretrained(\"asafaya/bert-base-arabic\").to(device)  # Déplacer le modèle sur le GPU","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:28:50.621543Z","iopub.execute_input":"2025-01-11T16:28:50.621878Z","iopub.status.idle":"2025-01-11T16:28:55.184390Z","shell.execute_reply.started":"2025-01-11T16:28:50.621824Z","shell.execute_reply":"2025-01-11T16:28:55.183674Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e62dc84d656a47e7b7162f2a57f2b863"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/334k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7327171ced13443a83d2eb8074045094"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b29adfe73c1244af88b9e65db971ca9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/491 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fb22d6e7c5447c6b86a26f0ef182fef"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f21eefcaa0384d2ab120f03a733f4010"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"def encode_text(text, tokenizer, max_length=350):\n    encoded = tokenizer.encode_plus(\n        text,\n        max_length=max_length,\n        truncation=True,\n        padding=\"max_length\",\n        return_tensors=\"pt\"\n    )\n    # Déplacer vers le GPU\n    return encoded[\"input_ids\"].to(device), encoded[\"attention_mask\"].to(device)\n\ndef get_bert_embeddings(text, tokenizer, model):\n    input_ids, attention_mask = encode_text(text, tokenizer)\n    \n    # Passer les données sur le GPU et exécuter le modèle sans calcul des gradients\n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n        embeddings = outputs.last_hidden_state\n        \n    # Retourner les embeddings du [CLS] token\n    return embeddings[:, 0, :].cpu().numpy()  # Déplacer vers le CPU avant de convertir en numpy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:28:55.185219Z","iopub.execute_input":"2025-01-11T16:28:55.185762Z","iopub.status.idle":"2025-01-11T16:28:55.191251Z","shell.execute_reply.started":"2025-01-11T16:28:55.185727Z","shell.execute_reply":"2025-01-11T16:28:55.190403Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Appliquer l'encodage et obtenir les embeddings pour chaque texte\ntrain_set['embedding'] = train_set['text'].apply(lambda x: get_bert_embeddings(x, tokenizer, model))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:28:55.192152Z","iopub.execute_input":"2025-01-11T16:28:55.192435Z","iopub.status.idle":"2025-01-11T16:31:42.559465Z","shell.execute_reply.started":"2025-01-11T16:28:55.192405Z","shell.execute_reply":"2025-01-11T16:31:42.558777Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Appliquer l'encodage et obtenir les embeddings pour chaque texte\ndev_set['embedding'] = dev_set['text'].apply(lambda x: get_bert_embeddings(x, tokenizer, model))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:31:42.560253Z","iopub.execute_input":"2025-01-11T16:31:42.560692Z","iopub.status.idle":"2025-01-11T16:32:20.160362Z","shell.execute_reply.started":"2025-01-11T16:31:42.560661Z","shell.execute_reply":"2025-01-11T16:32:20.159650Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Appliquer l'encodage et obtenir les embeddings pour chaque texte\ntest_set['embedding'] = test_set['text'].apply(lambda x: get_bert_embeddings(x, tokenizer, model))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:32:20.161112Z","iopub.execute_input":"2025-01-11T16:32:20.161398Z","iopub.status.idle":"2025-01-11T16:32:58.346454Z","shell.execute_reply.started":"2025-01-11T16:32:20.161369Z","shell.execute_reply":"2025-01-11T16:32:58.345794Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Extraire les embeddings et les étiquettes\nX_train = list(train_set['embedding'])  # Embeddings\ny_train = train_set['generated'].values  # Labels\n\n# Aplatir les embeddings\nX_train = [embedding.flatten() for embedding in X_train]\n\n# Diviser en données d'entraînement et de test\nX_test = list(dev_set['embedding'])\ny_test = dev_set['generated'].values  # Labels\n\n# Aplatir les embeddings\nX_test = [embedding.flatten() for embedding in X_test]\n\n\nX_submission = list(test_set['embedding'])  # Embeddings\nX_submission = [embedding.flatten() for embedding in X_submission]\n\n# Normaliser les embeddings\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nX_submission = scaler.transform(X_submission)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:32:58.347171Z","iopub.execute_input":"2025-01-11T16:32:58.347367Z","iopub.status.idle":"2025-01-11T16:32:58.500718Z","shell.execute_reply.started":"2025-01-11T16:32:58.347349Z","shell.execute_reply":"2025-01-11T16:32:58.500035Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"_ = '''\nfrom sklearn.model_selection import GridSearchCV\n\n# Paramètres à tester\nparam_grid = {\n    'C': [0.1, 1, 10],\n    'gamma': [0.001, 0.01, 0.1, 1],\n    'kernel': ['rbf', 'linear']\n}\n\n# Recherche par grille\ngrid_search = GridSearchCV(SVC(), param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\n\n# Affichage des meilleurs paramètres et du score\nprint(f\"Meilleurs paramètres: {grid_search.best_params_}\")\nprint(f\"Meilleur score: {grid_search.best_score_}\")\n'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:32:58.501369Z","iopub.execute_input":"2025-01-11T16:32:58.501585Z","iopub.status.idle":"2025-01-11T16:32:58.505657Z","shell.execute_reply.started":"2025-01-11T16:32:58.501567Z","shell.execute_reply":"2025-01-11T16:32:58.504761Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Récupérer les meilleurs paramètres du grid search\n# best_params = grid_search.best_params_\n\n# Créer et entraîner le modèle SVM avec les meilleurs paramètres\nsvm_best = SVC(C=10, gamma=0.001, kernel='rbf')\nsvm_best.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:32:58.506344Z","iopub.execute_input":"2025-01-11T16:32:58.506563Z","iopub.status.idle":"2025-01-11T16:33:00.418958Z","shell.execute_reply.started":"2025-01-11T16:32:58.506538Z","shell.execute_reply":"2025-01-11T16:33:00.418003Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"SVC(C=10, gamma=0.001)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, gamma=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, gamma=0.001)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Predict on development set\ny_dev_pred_rf_model = svm_best.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:33:00.419966Z","iopub.execute_input":"2025-01-11T16:33:00.420265Z","iopub.status.idle":"2025-01-11T16:33:00.892292Z","shell.execute_reply.started":"2025-01-11T16:33:00.420243Z","shell.execute_reply":"2025-01-11T16:33:00.891370Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Evaluate on development set\nprint(\"Development Set Evaluation:\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_dev_pred_rf_model)}\")\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_dev_pred_rf_model))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_dev_pred_rf_model))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:33:00.893260Z","iopub.execute_input":"2025-01-11T16:33:00.893580Z","iopub.status.idle":"2025-01-11T16:33:00.910448Z","shell.execute_reply.started":"2025-01-11T16:33:00.893550Z","shell.execute_reply":"2025-01-11T16:33:00.909778Z"}},"outputs":[{"name":"stdout","text":"Development Set Evaluation:\nAccuracy: 0.9979310344827587\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       707\n           1       1.00      1.00      1.00       743\n\n    accuracy                           1.00      1450\n   macro avg       1.00      1.00      1.00      1450\nweighted avg       1.00      1.00      1.00      1450\n\nConfusion Matrix:\n[[707   0]\n [  3 740]]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import joblib\n# Sauvegarder le modèle SVM dans un fichier\njoblib.dump(svm_best, 'svm_model_V2.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:33:00.911122Z","iopub.execute_input":"2025-01-11T16:33:00.911337Z","iopub.status.idle":"2025-01-11T16:33:00.921457Z","shell.execute_reply.started":"2025-01-11T16:33:00.911317Z","shell.execute_reply":"2025-01-11T16:33:00.920796Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"['svm_model_V2.pkl']"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"y_test_pred = svm_best.predict(X_submission)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:33:00.922352Z","iopub.execute_input":"2025-01-11T16:33:00.922665Z","iopub.status.idle":"2025-01-11T16:33:01.436426Z","shell.execute_reply.started":"2025-01-11T16:33:00.922632Z","shell.execute_reply":"2025-01-11T16:33:01.435778Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Create a DataFrame with the 'id' and predicted labels\nresults_df = pd.DataFrame({\n    'text_id': test_set['text_id'],\n    'generated': y_test_pred\n})\n\n# Save the DataFrame to a CSV file\nresults_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:33:01.437143Z","iopub.execute_input":"2025-01-11T16:33:01.437334Z","iopub.status.idle":"2025-01-11T16:33:01.446942Z","shell.execute_reply.started":"2025-01-11T16:33:01.437316Z","shell.execute_reply":"2025-01-11T16:33:01.446213Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"results_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:33:01.449602Z","iopub.execute_input":"2025-01-11T16:33:01.449833Z","iopub.status.idle":"2025-01-11T16:33:01.457961Z","shell.execute_reply.started":"2025-01-11T16:33:01.449813Z","shell.execute_reply":"2025-01-11T16:33:01.457236Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"      text_id  generated\n0        2227          1\n1        6682          0\n2        2649          1\n3        6652          0\n4        4296          1\n...       ...        ...\n1446     8450          0\n1447     6758          0\n1448     6452          0\n1449     5764          0\n1450     8792          0\n\n[1451 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2227</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6682</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2649</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6652</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4296</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1446</th>\n      <td>8450</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1447</th>\n      <td>6758</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1448</th>\n      <td>6452</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1449</th>\n      <td>5764</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1450</th>\n      <td>8792</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1451 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"results_df['generated'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:33:01.458965Z","iopub.execute_input":"2025-01-11T16:33:01.459267Z","iopub.status.idle":"2025-01-11T16:33:01.475232Z","shell.execute_reply.started":"2025-01-11T16:33:01.459235Z","shell.execute_reply":"2025-01-11T16:33:01.474536Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"generated\n1    744\n0    707\nName: count, dtype: int64"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}